{
    "args": {
        "accuracy": false,
        "audit_conf": "audit.config",
        "backend": "pytorch",
        "count": null,
        "dataset": "coco-1024",
        "dataset_path": "/root/CM/repos/local/cache/8dbcc4db51864d6b/install",
        "debug": false,
        "device": "cuda",
        "dtype": "fp32",
        "find_peak_performance": false,
        "ids_path": "tools/sample_ids.txt",
        "latent_framework": "torch",
        "max_batchsize": 1,
        "max_latency": null,
        "mlperf_conf": "/root/CM/repos/local/cache/659f64ae2e094a09/inference/mlperf.conf",
        "model_name": "stable-diffusion-xl",
        "model_path": null,
        "output": "/root/CM/repos/local/cache/8949b340a97343e2/test_results/hfx06h100dgx01-reference-gpu-pytorch-v2.3.0-default_config/stable-diffusion-xl/offline/performance/run_1",
        "performance_sample_count": 5000,
        "profile": "stable-diffusion-xl-pytorch",
        "qps": null,
        "samples_per_query": 8,
        "scenario": "Offline",
        "threads": 1,
        "time": null,
        "user_conf": "/root/CM/repos/gateoverflow@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/a8aed77a78b44d28ac0f7616e9497e1a.conf"
    },
    "cmdline": "Namespace(dataset='coco-1024', dataset_path='/root/CM/repos/local/cache/8dbcc4db51864d6b/install', profile='stable-diffusion-xl-pytorch', scenario='Offline', max_batchsize=1, threads=1, accuracy=False, find_peak_performance=False, backend='pytorch', model_name='stable-diffusion-xl', output='/root/CM/repos/local/cache/8949b340a97343e2/test_results/hfx06h100dgx01-reference-gpu-pytorch-v2.3.0-default_config/stable-diffusion-xl/offline/performance/run_1', qps=None, model_path=None, dtype='fp32', device='cuda', latent_framework='torch', mlperf_conf='/root/CM/repos/local/cache/659f64ae2e094a09/inference/mlperf.conf', user_conf='/root/CM/repos/gateoverflow@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/a8aed77a78b44d28ac0f7616e9497e1a.conf', audit_conf='audit.config', ids_path='tools/sample_ids.txt', time=None, count=None, debug=False, performance_sample_count=5000, max_latency=None, samples_per_query=8)",
    "runtime": "pytorch-SUT",
    "time": 1717228058,
    "version": "2.3.0+cu121"
}